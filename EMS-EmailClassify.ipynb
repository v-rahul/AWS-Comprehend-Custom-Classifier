{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import random\n",
    "import tarfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import JSON\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION:  ap-south-1\n",
      "ACCOUNT:  866834277637\n"
     ]
    }
   ],
   "source": [
    "#Account Details \n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "print('REGION: ',region)\n",
    "print('ACCOUNT: ',account_id)\n",
    "\n",
    "\n",
    "#Created S3 Bucket\n",
    "bucketName = 'myemailclassificationbucket'\n",
    "bucketArn = 'arn:aws:s3:::{}'.format(bucketName)\n",
    "iam = boto3.client('iam')\n",
    "roleName = 'comprehend-bucketAccessRole'\n",
    "roleArn=''\n",
    "policyName='comprehend-DataAccessRolePolicy'\n",
    "policyArn=''\n",
    "\n",
    "\n",
    "#ROLE will be assumed by Comprehend\n",
    "\n",
    "role_for_comprehend = {    \n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \n",
    "            {\n",
    "                \"Service\": \"comprehend.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]}\n",
    "\n",
    "\n",
    "policy_for_comprehend = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"{}/*\".format(bucketArn)\n",
    "            ],\n",
    "            \"Effect\": \"Allow\"\n",
    "        },\n",
    "        {\n",
    "            \"Action\": [\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"{}\".format(bucketArn)\n",
    "            ],\n",
    "            \"Effect\": \"Allow\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "#Create ROLE\n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "try:\n",
    "    create_role_res = iam.create_role(\n",
    "        RoleName=roleName,\n",
    "        AssumeRolePolicyDocument=json.dumps(role_for_comprehend),\n",
    "        Description='Comprehend Experiment Role',\n",
    "    )\n",
    "    roleArn = create_role_res['Role']['Arn']\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        roleArn = 'arn:aws:iam::{0}:role/{1}'.format(account_id, roleName)\n",
    "    else:\n",
    "        print('Unexpected error occurred')\n",
    "\n",
    "#Create Policy\n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "try:\n",
    "    policy_res = iam.create_policy(\n",
    "        PolicyName=policyName,\n",
    "        PolicyDocument=json.dumps(policy_for_comprehend)\n",
    "    )\n",
    "    policyArn = policy_res['Policy']['Arn']\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        policyArn = 'arn:aws:iam::{0}:policy/{1}'.format(account_id, policyName)\n",
    "    else:\n",
    "        print('Unexpected error occurred')\n",
    "        iam.delete_role(\n",
    "            RoleName= roleName\n",
    "        )\n",
    "\n",
    "\n",
    "# Attach the policy-role\n",
    "try:\n",
    "    policy_attach_res = iam.attach_role_policy(\n",
    "        RoleName=roleName,\n",
    "        PolicyArn=policyArn)\n",
    "\n",
    "except ClientError as error:\n",
    "    print('Unexpected error occurred')\n",
    "    iam.delete_role(\n",
    "        RoleName=roleName\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role ARN: \"arn:aws:iam::866834277637:role/comprehend-bucketAccessRole\"\n",
      "Policy ARN: \"arn:aws:iam::866834277637:policy/comprehend-DataAccessRolePolicy\"\n",
      "Bucket ARN: \"arn:aws:s3:::myemailclassificationbucket\"\n"
     ]
    }
   ],
   "source": [
    "print('Role ARN: \"{}\"'.format(roleArn))\n",
    "print('Policy ARN: \"{}\"'.format(policyArn))\n",
    "print('Bucket ARN: \"{}\"'.format(bucketArn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#DATA SET PREPARATION # REMOVING NON UNICODE \n",
    "import pandas as pd\n",
    "f = open('C:/Users/VMARA/OneDrive/Desktop/Python Codes/EmalDataset1.csv',encoding='UTF-8')\n",
    "lines = f.readlines()\n",
    "try:\n",
    "    for l in lines:\n",
    "        l.encode(encoding = 'UTF-8', errors = 'ignore')\n",
    "except:\n",
    "    print('Not able to encode')\n",
    "corpus = pd.DataFrame(lines)\n",
    "corpusdf = pd.DataFrame(corpus)\n",
    "corpusdf.columns = ['Class']\n",
    "\n",
    "corpusdf[['Class', 'Text']] = corpusdf.Class.str.split(',', n=1, expand=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PREPARING TEST AND TRAINING DATA\n",
    "\n",
    "TrainingDataset = corpusdf.sample(frac=0.8,random_state=3)\n",
    "TestDataSet = corpusdf.sample(frac=0.2,random_state=25)\n",
    "\n",
    "#print(TrainingDataset[TrainingDataset[\"Class\"] == \"\\\"\\\"\"])\n",
    "\n",
    "#FILNAMES\n",
    "\n",
    "TrainFile = 'TrainingDataset.csv'\n",
    "TestFile = 'TestDataset.csv'\n",
    "\n",
    "TrainingDataset.to_csv('C:/Users/VMARA/OneDrive/Desktop/Python Codes/'+TrainFile, header=None, index=False)\n",
    "TestDataSet.to_csv('C:/Users/VMARA/OneDrive/Desktop/Python Codes/'+TestFile,header=None, index=False)\n",
    "\n",
    "\n",
    "# UPLOAD FILE IN S3\n",
    "s3 = boto3.client('s3')\n",
    "status = s3.upload_file('C:/Users/VMARA/OneDrive/Desktop/Python Codes/'+TrainFile,'myemailclassificationbucket',TrainFile)\n",
    "\n",
    "#Training file URI\n",
    "training_file = 's3://myemailclassificationbucket/1'+TrainFile\n",
    "outputfolder = 's3://myemailclassificationbucket/train/output/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classifier with the name \"Custom-E-Classifier\" already exists.\n",
      "Document Classifier ARN: arn:aws:comprehend:ap-south-1:866834277637:document-classifier/Custom-E-Classifier\n"
     ]
    }
   ],
   "source": [
    "# Creating Custom Classifier\n",
    "customClassifier = 'Custom-E-Classifier'\n",
    "customclassifierArn= ''\n",
    "\n",
    "comprehend = boto3.client('comprehend')\n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "try:\n",
    "    response = comprehend.create_document_classifier(\n",
    "        DocumentClassifierName=customClassifier,\n",
    "        DataAccessRoleArn=roleArn,\n",
    "        InputDataConfig={\n",
    "            'DataFormat': 'COMPREHEND_CSV',\n",
    "            'S3Uri': training_file\n",
    "        },\n",
    "        OutputDataConfig={\n",
    "            'S3Uri': outputfolder\n",
    "        },\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    document_classifier_arn = response['DocumentClassifierArn']\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'ResourceInUseException':\n",
    "        print('A classifier with the name \"{0}\" already exists.'.format(customClassifier))\n",
    "        document_classifier_arn = 'arn:aws:comprehend:{0}:{1}:document-classifier/{2}'.format(region, account_id, customClassifier)\n",
    "print('Document Classifier ARN: ' + document_classifier_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRAINED'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn=document_classifier_arn\n",
    "    )\n",
    "status = response['DocumentClassifierProperties']['Status']\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocumentClassifierArn': 'arn:aws:comprehend:ap-south-1:866834277637:document-classifier/Custom-E-Classifier', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2022, 7, 8, 11, 6, 42, 716000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2022, 7, 8, 12, 8, 56, 955000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2022, 7, 8, 11, 10, 33, 882000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2022, 7, 8, 12, 7, 59, 920000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'S3Uri': 's3://myemailclassificationbucket/1TrainingDataset.csv'}, 'OutputDataConfig': {'S3Uri': 's3://myemailclassificationbucket/train/output/866834277637-CLR-0fb9c1e0c3097a135d064560513e604a/output/output.tar.gz'}, 'ClassifierMetadata': {'NumberOfLabels': 2, 'NumberOfTrainedDocuments': 4010, 'NumberOfTestDocuments': 445, 'EvaluationMetrics': {'Accuracy': 0.9933, 'Precision': 0.9961, 'Recall': 0.975, 'F1Score': 0.9852, 'MicroPrecision': 0.9933, 'MicroRecall': 0.9933, 'MicroF1Score': 0.9933, 'HammingLoss': 0.0067}}, 'DataAccessRoleArn': 'arn:aws:iam::866834277637:role/comprehend-bucketAccessRole', 'Mode': 'MULTI_CLASS'}\n"
     ]
    }
   ],
   "source": [
    "print(response['DocumentClassifierProperties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An endpoint with the name \"Custom-E-Classifier-endpoint\" already exists.\n",
      "Document Classifier Endpoint ARN: arn:aws:comprehend:ap-south-1:866834277637:document-classifier-endpoint/Custom-E-Classifier-endpoint\n"
     ]
    }
   ],
   "source": [
    "#CREATING ENDPOINT FOR REAL TIME ANALYSIS\n",
    "client = boto3.client('comprehend')\n",
    "region = boto3.session.Session().region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "realtime_endpoint_name = customClassifier + '-endpoint'\n",
    "try:\n",
    "    response = client.create_endpoint(\n",
    "        EndpointName=realtime_endpoint_name,\n",
    "        ModelArn=document_classifier_arn,\n",
    "        DesiredInferenceUnits=10\n",
    "    )\n",
    "    endpoint_arn = response['EndpointArn']\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'ResourceInUseException':\n",
    "        print('An endpoint with the name \"{0}\" already exists.'.format(realtime_endpoint_name))\n",
    "        endpoint_arn = 'arn:aws:comprehend:{0}:{1}:document-classifier-endpoint/{2}'.format(region, account_id, realtime_endpoint_name)\n",
    "print('Document Classifier Endpoint ARN: ' + endpoint_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_SERVICE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "status = response['EndpointProperties']['Status']\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST \n",
    "\n",
    "test_emails = 'TestDataSet.csv'\n",
    "column = ['CLASS','TEXT']\n",
    "test_df = pd.read_csv('C:/Users/VMARA/OneDrive/Desktop/Python Codes/'+test_emails, names=column)\n",
    "test_df\n",
    "\n",
    "sample_email = '''\n",
    "\"Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed Ã¥Â£1000 cash or Ã¥Â£5000 prize!\n",
    "\"\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.classify_document(Text=sample_email,EndpointArn=endpoint_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['Classes'][0]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,25):\n",
    "    response = client.classify_document(Text=test_df['CLASS'][i],EndpointArn=endpoint_arn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ab0f08ab160772d0d7f8183fa4cc13221b4c1a08d03b10a240336a0657000ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
